{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"Effortless Task Management: Flexible, Fast, Simple and Reliable"},{"location":"#overview","title":"Overview","text":"<p>Taskade is a Python framework designed to simplify the execution of tasks with dependencies. It provides a flexible and efficient way to manage task execution, allowing developers to focus on writing task logic rather than managing dependencies.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>High Performance: Optimized for speed and efficiency.</li> <li>Easy to Use: Simple and intuitive API.</li> <li>Lightweight: Taskade has no dependencies on anything outside of the standard library.</li> <li>Flexible Execution: Choose from various execution strategies, including sequential, concurrent, and asynchronous execution.</li> <li>CGraphLib: An C Extension intended to replace python graphlib, cgraphlib. With up to a ~2.5x performance improvement over the standard library.</li> </ul>"},{"location":"#design-principles","title":"Design Principles","text":"<p>Taskade is designed with the following principles in mind:</p> <ul> <li>Separation of Concerns: Task logic is separate from execution logic.</li> <li>Flexibility: Support for various execution strategies and task types.</li> <li>Efficiency: Optimize task execution for performance.</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>Taskade is suitable for applications that require:</p> <ul> <li>Complex Task Dependencies: Manage complex task dependencies with ease.</li> <li>High-Performance Execution: Execute tasks concurrently for improved performance.</li> <li>Asynchronous Tasks: Support for asynchronous tasks and execution.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install Taskade, you can use pip or your preferred package manager.</p> <pre><code>pip install taskade\n</code></pre> <p>Tip</p> <p>To get the full speed improvement for larger DAGs execute taskade with the cgraphlib optional dependency. See cgraphlib for more information. cgraphlib is enabled by default and python graphlib can be used by setting the environment variable <code>USE_PYGRAPHLIB</code> to <code>true</code>.</p> <p>After installation head over to the quick start page to get started with creating and executing graphs.</p>"},{"location":"cgraphlib/","title":"CGraphLib","text":""},{"location":"cgraphlib/#introduction","title":"Introduction","text":"<p>cgraphlib is a C extension for Python that provides a more efficient implementation of the internal toplogical graph sorter. This is the default implementation Taskade uses for execution.</p> <p>The extension was inspired by graphlib. The other advantage is that coupled with the fact that taskade has no dependencies it is possible to still use taskade on versions of python that don't support graphlib.</p>"},{"location":"cgraphlib/#benchmark","title":"Benchmark","text":"<p>To benchmark the performance of Taskade, we will be using the benchmark.py script by calling benchmark.sh. This script will create a random DAG with a specified number of tasks and dependencies, and then execute the DAG using Taskade and a few other popular libraries.</p> Execution Type Task Count cgraphlib Avg \u00b1 Std (s) pygraphlib Avg \u00b1 Std (s) cgraphlib x faster Sync 1 0.000112 \u00b1 0.000008 0.000123 \u00b1 0.000004 1.10 Sync 10 0.000743 \u00b1 0.000012 0.000798 \u00b1 0.000024 1.07 Sync 100 0.017548 \u00b1 0.000144 0.029783 \u00b1 0.000235 1.70 Sync 500 0.238663 \u00b1 0.001475 0.555585 \u00b1 0.003965 2.33 Sync 1000 0.570467 \u00b1 0.010899 1.391227 \u00b1 0.020914 2.44 Sync 5000 3.860468 \u00b1 0.060122 9.574127 \u00b1 0.053635 2.48 Sync 10000 8.330627 \u00b1 0.055351 20.504808 \u00b1 0.248797 2.46 Sync 50000 53.619465 \u00b1 0.318738 123.350060 \u00b1 0.548668 2.30 Sync 100000 141.262903 \u00b1 0.509695 290.261497 \u00b1 0.827542 2.05 Threaded 1 0.000308 \u00b1 0.000068 0.000369 \u00b1 0.000095 1.20 Threaded 10 0.001401 \u00b1 0.000135 0.001436 \u00b1 0.000094 1.03 Threaded 100 0.019505 \u00b1 0.000144 0.031843 \u00b1 0.000247 1.63 Threaded 500 0.242867 \u00b1 0.001770 0.566135 \u00b1 0.002655 2.33 Threaded 1000 0.571698 \u00b1 0.005058 1.421466 \u00b1 0.004682 2.49 Threaded 5000 3.887257 \u00b1 0.051935 9.790658 \u00b1 0.119144 2.52 Threaded 10000 8.609358 \u00b1 0.085867 21.039031 \u00b1 0.219296 2.44 Threaded 50000 58.770154 \u00b1 0.301631 131.879641 \u00b1 0.322479 2.24 Threaded 100000 155.800541 \u00b1 0.653699 311.092993 \u00b1 0.508799 2.00 Process 1 1.977064 \u00b1 0.679840 2.682294 \u00b1 0.927356 1.36 Process 10 1.975413 \u00b1 0.677598 2.676924 \u00b1 0.924303 1.36 Process 100 2.015815 \u00b1 0.678133 2.728529 \u00b1 0.923138 1.35 Process 500 2.289209 \u00b1 0.676583 3.311899 \u00b1 0.922781 1.45 Process 1000 2.675230 \u00b1 0.669569 4.204118 \u00b1 0.919089 1.57 Process 5000 6.487916 \u00b1 0.661428 13.031447 \u00b1 0.924691 2.01 Process 10000 11.832457 \u00b1 0.659005 25.058576 \u00b1 0.857200 2.12 Process 50000 70.737856 \u00b1 1.080970 146.915526 \u00b1 0.944690 2.08 Process 100000 190.708719 \u00b1 1.356575 353.259943 \u00b1 0.801520 1.85 Async 1 0.000131 \u00b1 0.000015 0.000145 \u00b1 0.000013 1.10 Async 10 0.000490 \u00b1 0.000015 0.000554 \u00b1 0.000008 1.13 Async 100 0.012828 \u00b1 0.000110 0.024954 \u00b1 0.000117 1.95 Async 500 0.205863 \u00b1 0.001378 0.520926 \u00b1 0.003159 2.53 Async 1000 0.500223 \u00b1 0.003213 1.321445 \u00b1 0.010514 2.64 Async 5000 3.429843 \u00b1 0.035481 9.155247 \u00b1 0.077005 2.67 Async 10000 7.529800 \u00b1 0.069054 19.617411 \u00b1 0.184248 2.61 Async 50000 49.364607 \u00b1 0.270251 120.704542 \u00b1 0.377445 2.45 Async 100000 133.263472 \u00b1 0.751990 291.191692 \u00b1 2.279661 2.19"},{"location":"license/","title":"License","text":"<p>Copyright 2024 Alexander Epstein</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"quick_start/","title":"Quick Start","text":"<p>Creating and exeucting graphs in Taskade is simple and flexible.</p>"},{"location":"quick_start/#sync-tasks","title":"Sync Tasks","text":"<p>To create a Task, use the @task decorator:</p> <pre><code>from taskade import task\n\n@task(graph_name='my_graph')\ndef my_task():\n    # Task implementation\n    return \"example_output\"\n\n@task(graph_name=\"my_graph\", dependencies=my_task)\ndef my_final_task(dependent_result)\n    print(dependent_result)\n    return \"final_example_output\"\n</code></pre> <p>Using the decorator automatically creates a Graph and allows it to be executed.</p> <pre><code>from taskade import get_graph\n\ndef main():\n    results = get_graph(\"my_graph\")() # Call the execution of the graph\n    print(results[my_task]) # Prints `example_output`\n    print(results[my_final_task]) # Prints `final_example_output`\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"quick_start/#async-tasks","title":"Async Tasks","text":"<p>Allowing for async execution is as easy as having tasks that are async functions and using the <code>await</code> keyword when calling the graph execution.</p> <pre><code>from taskade import task, get_graph\nimport asyncio\n\n@task(graph_name='my_graph')\nasync def my_task():\n    # Task implementation\n    return \"example_output\"\n\n@task(graph_name=\"my_graph\", dependencies=my_task)\nasync def my_final_task(dependent_result)\n    print(dependent_result)\n    return \"final_example_output\"\n\nasync def main():\n    results = await get_graph(\"my_graph\")() # Call the execution of the graph with await\n    print(results[my_task]) # Prints `example_output`\n    print(results[my_final_task]) # Prints `final_example_output`\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"quick_start/#combine-sync-async-tasks","title":"Combine Sync &amp; Async Tasks","text":"<p>Taskade graphs also allow for mixing async and sync tasks within the same graph. Blocking will occur only when an sync function is executing, but otherwise the same async behavior will be preserved. </p> <pre><code>from taskade import task\n\n@task(graph_name='my_graph')\nasync def my_task():\n    # Task implementation\n    return \"example_output\"\n\n@task(graph_name=\"my_graph\", dependencies=my_task)\ndef my_final_task(dependent_result)\n    print(dependent_result)\n</code></pre> <p>you will still need to execute the graph using <code>await</code> as some of the nodes are async.</p> <pre><code>from taskade import get_graph\nimport asyncio\n\nasync def main():\n    results = await get_graph(\"my_graph\")() # Call the execution of the graph\n    print(results[my_task]) # Prints `example_output`\n    print(results[my_final_task]) # Prints `final_example_output`\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"development/","title":"Development","text":""},{"location":"development/#setting-up-the-environment","title":"Setting up the Environment","text":"<p>To set up the environment for development, install  and run the following command:</p> <pre><code>pdm install -G :all\n</code></pre> <p>This will install all the dependencies required for development.</p>"},{"location":"development/#user-scripts","title":"User Scripts","text":"<p>The following user scripts are available to make development easier:</p> <pre><code>* pre-commit: Run pre-commit hooks on all files.\n* serve-document: Serve the documentation locally.\n* document: Build the documentation.\n* test: Run tests with coverage reporting.\n* format: Format code using ruff and isort.\n* release: Run pre-commit, tests, and build documentation (composite script).\n</code></pre> <p>These scripts can be run using the following command:</p> <p><code>pdm run &lt;script_name&gt;</code></p> <p>Replace <code>&lt;script_name&gt;</code> with the name of the script you want to run.</p> <p>Alex Epstein</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>taskade<ul> <li>_decorator</li> <li>_exceptions</li> <li>_execution</li> <li>_types</li> <li>cgraphlib</li> </ul> </li> </ul>"},{"location":"reference/taskade/","title":"Index","text":""},{"location":"reference/taskade/#taskade.Graph","title":"<code>Graph</code>","text":"<p>The graph object, tying together multiple tasks together for execution of a DAG</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class Graph:\n    \"\"\"The graph object, tying together multiple tasks together for execution of a DAG\"\"\"\n\n    def __init__(\n        self,\n        tasks: Optional[Tuple[Task, ...]] = None,\n        name: Optional[str] = None,\n        initial_capacity: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initializer for the graph\n\n        :param tasks: tuple of tasks tied to this graph, defaults to None\n        :param name: the identifier for the graph, defaults to None\n        :param initial_capactiy: the initial capacity of the graph, only applicable to cgraphlib, defaults to None\n        \"\"\"\n        super().__init__()\n        self._results: Optional[GraphResults] = None\n        self.__graph_add = self.__c_graph_add if __cgraphlib__ else self.__std_graph_add\n        if initial_capacity:\n            if __cgraphlib__:\n                self.__graph = TopologicalSorter(initial_capacity)  # type: ignore fix for cgraphlib\n            else:\n                log.warning(\"Initial capacity is only applicable to cgraphlib, ignoring.\")\n                self.__graph = TopologicalSorter()\n        else:\n            self.__graph = TopologicalSorter()\n        self.name = name\n        self.__is_async = False\n        self._node_to_dependencies: Dict[Task, Tuple[Task, ...]] = {}\n        if tasks:\n            for task in tasks:\n                self._node_to_dependencies[task] = task.dependencies\n                self.__graph_add(task)\n                if not self.__is_async:\n                    self.__is_async = task.is_async\n        if self.name:\n            _get_graph()[self.name] = self\n\n    def __del__(self):\n        \"\"\"\n        Destructor for the graph, removes the graph from the global graph dictionary\n        \"\"\"\n        try:\n            delete_graph(self.name)\n        except KeyError:\n            pass\n        for task in self._node_to_dependencies:\n            task._graph = None  # Remove the reference to the graph\n\n    def __c_graph_add(self: Graph, task: Task) -&gt; None:\n        \"\"\"\n        Adds a task to the graph when using cgraphlib\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        self.__graph.add(task, task.dependencies)\n\n    def __std_graph_add(self: Graph, task: Task) -&gt; None:\n        \"\"\"\n        Adds a task to the graph when using std graphlib\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        self.__graph.add(task, *task.dependencies)\n\n    def __getitem__(self, key: str) -&gt; Task:\n        \"\"\"\n        Gets the task by name in the graph\n\n        :param key: the name of the task to retrieve\n        :raises KeyError: raised if the task is not found in the graph\n        :return: the task object\n        \"\"\"\n        for task in self._node_to_dependencies:\n            if task.name == key:\n                return task\n        raise KeyError(f\"Task {key} not found in graph.\")\n\n    @classmethod\n    def from_list(\n        cls: Type[Graph],\n        graph_name: str,\n        tasks_list: List[Dict[str, str]],\n        func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n    ) -&gt; Graph:\n        \"\"\"\n        Create a graph from a list of tasks\n\n        :param cls: the class object of the graph\n        :param graph_name: the name of the graph to create\n        :param tasks_list: the list of tasks to add to the graph\n        :param func_map: optional mapping of function names to their function, defaults to None\n        :return: the graph object\n        \"\"\"\n        graph = cls(name=graph_name)\n        for task_dict in tasks_list:\n            graph += Task.from_dict(task_dict, func_map)\n        return graph\n\n    @property\n    def low_level_graph(self: Graph) -&gt; TopologicalSorter:\n        \"\"\"\n        The low level graph object\n\n        :return: the low level graph object\n        \"\"\"\n        return self.__graph\n\n    @property\n    def unsorted_graph(self: Graph) -&gt; Dict[Task, Tuple[Task, ...]]:\n        \"\"\"\n        The unsorted version of the graph\n\n        :return: the dictionary of task to its dependencies\n        \"\"\"\n        return self._node_to_dependencies\n\n    @property\n    def is_async(self: Graph) -&gt; bool:\n        \"\"\"\n        Indicates if the graph is async\n\n        :return: true if any node in the graph is async, otherwise false\n        \"\"\"\n        return self.__is_async\n\n    def __add__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n        \"\"\"\n        Addition operator\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        if isinstance(tasks, Task):\n            tasks = (tasks,)\n        for task in tasks:\n            if not self.__is_async:\n                self.__is_async = task.is_async\n            if task._graph is not None:\n                if task.graph != self:\n                    raise ValueError(f\"Task {task.name} is already part of a different graph.\")\n            task._graph = self\n            self._node_to_dependencies[task] = task.dependencies\n            self.__graph_add(task)\n        return self\n\n    def __iadd__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n        \"\"\"\n        In place addition operator for adding a task to the graph\n\n        :param tasks: the task or tuple of tasks to add to the graph\n        :return: the graph itself\n        \"\"\"\n        return self + tasks\n\n    def execute(\n        self: Graph,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        raise_immediately: bool = True,\n        tasks_semaphore: Optional[asyncio.Semaphore] = None,\n        concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n        n_jobs: Optional[int] = None,\n    ) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n        \"\"\"\n        Executes the graph\n\n        :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n        :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n        :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n        if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n        :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n        :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n        can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n        :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n        :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n        :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n        \"\"\"\n        if self.is_async:\n            return aexecute_graph(self, pre_call, post_call, raise_immediately, tasks_semaphore)\n        else:\n            return execute_graph(self, pre_call, post_call, raise_immediately, concurrency_pool, n_jobs)\n\n    def __call__(\n        self: Graph,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        raise_immediately: bool = True,\n        tasks_semaphore: Optional[asyncio.Semaphore] = None,\n        concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n        n_jobs: Optional[int] = None,\n    ) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n        \"\"\"\n            Executes the graph\n            :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n            :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n            :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n            if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n            :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n            :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n        can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n        :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n            :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n            :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n        \"\"\"\n        return self.execute(pre_call, post_call, raise_immediately, tasks_semaphore, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.is_async","title":"<code>is_async: bool</code>  <code>property</code>","text":"<p>Indicates if the graph is async</p> <p>Returns:</p> Type Description <code>bool</code> <p>true if any node in the graph is async, otherwise false</p>"},{"location":"reference/taskade/#taskade.Graph.low_level_graph","title":"<code>low_level_graph: TopologicalSorter</code>  <code>property</code>","text":"<p>The low level graph object</p> <p>Returns:</p> Type Description <code>TopologicalSorter</code> <p>the low level graph object</p>"},{"location":"reference/taskade/#taskade.Graph.unsorted_graph","title":"<code>unsorted_graph: Dict[Task, Tuple[Task, ...]]</code>  <code>property</code>","text":"<p>The unsorted version of the graph</p> <p>Returns:</p> Type Description <code>Dict[Task, Tuple[Task, ...]]</code> <p>the dictionary of task to its dependencies</p>"},{"location":"reference/taskade/#taskade.Graph.__add__","title":"<code>__add__(tasks)</code>","text":"<p>Addition operator</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __add__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n    \"\"\"\n    Addition operator\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    if isinstance(tasks, Task):\n        tasks = (tasks,)\n    for task in tasks:\n        if not self.__is_async:\n            self.__is_async = task.is_async\n        if task._graph is not None:\n            if task.graph != self:\n                raise ValueError(f\"Task {task.name} is already part of a different graph.\")\n        task._graph = self\n        self._node_to_dependencies[task] = task.dependencies\n        self.__graph_add(task)\n    return self\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__c_graph_add","title":"<code>__c_graph_add(task)</code>","text":"<p>Adds a task to the graph when using cgraphlib</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>None</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __c_graph_add(self: Graph, task: Task) -&gt; None:\n    \"\"\"\n    Adds a task to the graph when using cgraphlib\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    self.__graph.add(task, task.dependencies)\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__call__","title":"<code>__call__(pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<pre><code>Executes the graph\n:param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n:param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n:param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\nif False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n:param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n:param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n</code></pre> <p>can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type</p> <p>Parameters:</p> Name Type Description Default <code>n_jobs</code> <code>Optional[int]</code> <p>only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution</p> <code>None</code> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __call__(\n    self: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n    concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n    \"\"\"\n        Executes the graph\n        :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n        :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n        :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n        if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n        :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n        :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n    :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n        :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n        :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n    \"\"\"\n    return self.execute(pre_call, post_call, raise_immediately, tasks_semaphore, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__del__","title":"<code>__del__()</code>","text":"<p>Destructor for the graph, removes the graph from the global graph dictionary</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __del__(self):\n    \"\"\"\n    Destructor for the graph, removes the graph from the global graph dictionary\n    \"\"\"\n    try:\n        delete_graph(self.name)\n    except KeyError:\n        pass\n    for task in self._node_to_dependencies:\n        task._graph = None  # Remove the reference to the graph\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Gets the task by name in the graph</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>the name of the task to retrieve</p> required <p>Returns:</p> Type Description <code>Task</code> <p>the task object</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>raised if the task is not found in the graph</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Task:\n    \"\"\"\n    Gets the task by name in the graph\n\n    :param key: the name of the task to retrieve\n    :raises KeyError: raised if the task is not found in the graph\n    :return: the task object\n    \"\"\"\n    for task in self._node_to_dependencies:\n        if task.name == key:\n            return task\n    raise KeyError(f\"Task {key} not found in graph.\")\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__iadd__","title":"<code>__iadd__(tasks)</code>","text":"<p>In place addition operator for adding a task to the graph</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Union[Task, Tuple[Task, ...]]</code> <p>the task or tuple of tasks to add to the graph</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __iadd__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n    \"\"\"\n    In place addition operator for adding a task to the graph\n\n    :param tasks: the task or tuple of tasks to add to the graph\n    :return: the graph itself\n    \"\"\"\n    return self + tasks\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__init__","title":"<code>__init__(tasks=None, name=None, initial_capacity=None)</code>","text":"<p>Initializer for the graph</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tuple[Task, ...]]</code> <p>tuple of tasks tied to this graph, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>the identifier for the graph, defaults to None</p> <code>None</code> <code>initial_capactiy</code> <p>the initial capacity of the graph, only applicable to cgraphlib, defaults to None</p> required Source code in <code>src/taskade/_execution.py</code> <pre><code>def __init__(\n    self,\n    tasks: Optional[Tuple[Task, ...]] = None,\n    name: Optional[str] = None,\n    initial_capacity: Optional[int] = None,\n) -&gt; None:\n    \"\"\"\n    Initializer for the graph\n\n    :param tasks: tuple of tasks tied to this graph, defaults to None\n    :param name: the identifier for the graph, defaults to None\n    :param initial_capactiy: the initial capacity of the graph, only applicable to cgraphlib, defaults to None\n    \"\"\"\n    super().__init__()\n    self._results: Optional[GraphResults] = None\n    self.__graph_add = self.__c_graph_add if __cgraphlib__ else self.__std_graph_add\n    if initial_capacity:\n        if __cgraphlib__:\n            self.__graph = TopologicalSorter(initial_capacity)  # type: ignore fix for cgraphlib\n        else:\n            log.warning(\"Initial capacity is only applicable to cgraphlib, ignoring.\")\n            self.__graph = TopologicalSorter()\n    else:\n        self.__graph = TopologicalSorter()\n    self.name = name\n    self.__is_async = False\n    self._node_to_dependencies: Dict[Task, Tuple[Task, ...]] = {}\n    if tasks:\n        for task in tasks:\n            self._node_to_dependencies[task] = task.dependencies\n            self.__graph_add(task)\n            if not self.__is_async:\n                self.__is_async = task.is_async\n    if self.name:\n        _get_graph()[self.name] = self\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.__std_graph_add","title":"<code>__std_graph_add(task)</code>","text":"<p>Adds a task to the graph when using std graphlib</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>None</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __std_graph_add(self: Graph, task: Task) -&gt; None:\n    \"\"\"\n    Adds a task to the graph when using std graphlib\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    self.__graph.add(task, *task.dependencies)\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.execute","title":"<code>execute(pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<p>Executes the graph</p> <p>Parameters:</p> Name Type Description Default <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>tasks_semaphore</code> <code>Optional[Semaphore]</code> <p>only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None</p> <code>None</code> <code>concurrency_pool</code> <code>PoolExecutor</code> <p>only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks, can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type</p> <code>ThreadPoolExecutor</code> <code>n_jobs</code> <code>Optional[int]</code> <p>only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GraphResults, Awaitable[GraphResults]]</code> <p>if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def execute(\n    self: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n    concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n    \"\"\"\n    Executes the graph\n\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n    :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n    :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n    \"\"\"\n    if self.is_async:\n        return aexecute_graph(self, pre_call, post_call, raise_immediately, tasks_semaphore)\n    else:\n        return execute_graph(self, pre_call, post_call, raise_immediately, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/#taskade.Graph.from_list","title":"<code>from_list(graph_name, tasks_list, func_map=None)</code>  <code>classmethod</code>","text":"<p>Create a graph from a list of tasks</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Graph]</code> <p>the class object of the graph</p> required <code>graph_name</code> <code>str</code> <p>the name of the graph to create</p> required <code>tasks_list</code> <code>List[Dict[str, str]]</code> <p>the list of tasks to add to the graph</p> required <code>func_map</code> <code>Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]]</code> <p>optional mapping of function names to their function, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Graph</code> <p>the graph object</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>@classmethod\ndef from_list(\n    cls: Type[Graph],\n    graph_name: str,\n    tasks_list: List[Dict[str, str]],\n    func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n) -&gt; Graph:\n    \"\"\"\n    Create a graph from a list of tasks\n\n    :param cls: the class object of the graph\n    :param graph_name: the name of the graph to create\n    :param tasks_list: the list of tasks to add to the graph\n    :param func_map: optional mapping of function names to their function, defaults to None\n    :return: the graph object\n    \"\"\"\n    graph = cls(name=graph_name)\n    for task_dict in tasks_list:\n        graph += Task.from_dict(task_dict, func_map)\n    return graph\n</code></pre>"},{"location":"reference/taskade/#taskade.Task","title":"<code>Task</code>","text":"<p>The task object, wrapping a function and its dependencies</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class Task:\n    \"\"\"The task object, wrapping a function and its dependencies\"\"\"\n\n    def __init__(\n        self,\n        func: Callable[..., Union[Any, Awaitable[Any]]],\n        dependencies: Optional[Union[Task, Tuple[Task, ...]]] = None,\n        output_names: Optional[Tuple[str, ...]] = None,\n        *,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        init_kwargs: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n        _graph: Optional[Graph] = None,\n    ):\n        \"\"\"\n        Initialize a Task object.\n\n        :param func: The function that the task is wrapping\n        :param dependencies: The dependencies of the task, defaults to None\n        :param output_names: The names of the outputs of the task, defaults to None\n        :param pre_call: The function to call with the results of the dependencies for this task, defaults to None\n        :param post_call: The function to call with the output of this task, defaults to None\n        :param init_kwargs: The optional initialization arguments for the task if not provided all input arguments will\n        be provided by the dependency results, defaults to None\n        :param name: The optional name for this task, defaults to None\n        :param _graph: The optional graph for this task, defaults to None\n        \"\"\"\n        self.func = func\n        self.output_names: Tuple[str, ...] = output_names if output_names is not None else ()\n        self.pre_call = pre_call\n        self.post_call = post_call\n        self.init_kwargs = init_kwargs\n        self.name = name if name is not None else str(uuid4())\n        self._graph = _graph\n\n        if dependencies is None:\n            self.dependencies = ()\n        elif isinstance(dependencies, Task):\n            self.dependencies = (dependencies,)\n        else:\n            self.dependencies = cast(Tuple[Task, ...], dependencies)\n\n        if len(self.dependencies) &gt; 0:\n            for dependent_task in self.dependencies:\n                self._set_graph(dependent_task)\n        elif self._graph is not None:  # For task graphs where no dependencies are provided\n            cast(Graph, self.graph) + self\n\n    def __call__(self, *args, **kwargs) -&gt; Union[_T, Awaitable[_T]]:\n        \"\"\"\n        Executes the function within the task\n\n        :return: the results of the execution, if the function is async this will return the awaitable\n        \"\"\"\n        return self.func(*args, **kwargs)\n\n    @classmethod\n    def from_dict(\n        cls: Type[Task],\n        task_dict: Dict[str, Any],\n        func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n    ) -&gt; Task:\n        \"\"\"\n        Create a task from a dictionary\n\n        :param task_dict: the dictionary of the task\n        :param func_map: the mapping of the function names to the functions\n        :return: the task object\n        \"\"\"\n        func = task_dict.pop(\"func\")\n        if func_map and func in func_map:\n            task = cls(func_map[func], **task_dict)\n        else:\n            # Attempt to import the function dynamically\n            module_name, func_name = func.rsplit(\".\", 1)\n            module = import_module(module_name)\n            # Check type of func to ensure it is a callable\n            func = getattr(module, func_name)\n            if not isinstance(func, Callable):\n                raise ValueError(f\"Function {func_name} in module {module_name} is not callable.\")\n            func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n            task = cls(func, **task_dict)\n        task_dict[\"func\"] = func\n        return task\n\n    def _set_graph(self: Task, other: Task) -&gt; None:\n        \"\"\"\n        Ensures that this task and another task are tied to the same graph,\n\n        :param other: the other task tied to this task\n        :raises ValueError: if both tasks have a graph and they are not the same graph\n        \"\"\"\n        if self._graph is None:\n            graph = other.graph\n            if graph is not None:\n                self._graph = graph\n                graph + self\n            else:\n                self._graph = Graph((self, other))\n                other._graph = self._graph\n        else:\n            if other.graph is not None and self.graph != other.graph:\n                raise ValueError(f\"Task {self.name} and Task {other.name} are in different graphs.\")\n            graph = cast(Graph, self.graph)\n            graph + other\n\n    @property\n    def is_async(self: Task) -&gt; bool:\n        \"\"\"\n        Indicates if the task is async\n\n        :return: true if the task is async, false otherwise\n        \"\"\"\n        return asyncio.iscoroutinefunction(self.func)\n\n    @property\n    def graph(self: Task) -&gt; Optional[Graph]:\n        \"\"\"\n        The underlying graph for the task\n\n        :return: the graph for the task, this will be None if this task is not part of a graph\n        \"\"\"\n        return self._graph\n\n    def __hash__(self: Task) -&gt; int:\n        \"\"\"\n        Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)\n\n        :return: the hash for the task, which is a hash of the name\n        \"\"\"\n        return hash(self.name)\n\n    def __and__(self: Task, other: Union[Task, Tuple[Task, ...]]) -&gt; Tuple[Task, ...]:\n        \"\"\"\n        Binary and operator for the task or a tuple of tasks\n        This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n        :param other: the task being `anded` with this task\n        :return: a tuple of this task and the one being added\n        \"\"\"\n        return (self, other) if isinstance(other, Task) else (self, *other)\n\n    def __rand__(self: Task, other: Task) -&gt; Tuple[Task, ...]:\n        \"\"\"\n        Binary rand operator for the task or a tuple of tasks\n        This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n        :param other: the task being `anded` with this task\n        :return: a tuple of this task and the one being added\n        \"\"\"\n        return (other, self) if isinstance(other, Task) else (*other, self)\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.graph","title":"<code>graph: Optional[Graph]</code>  <code>property</code>","text":"<p>The underlying graph for the task</p> <p>Returns:</p> Type Description <code>Optional[Graph]</code> <p>the graph for the task, this will be None if this task is not part of a graph</p>"},{"location":"reference/taskade/#taskade.Task.is_async","title":"<code>is_async: bool</code>  <code>property</code>","text":"<p>Indicates if the task is async</p> <p>Returns:</p> Type Description <code>bool</code> <p>true if the task is async, false otherwise</p>"},{"location":"reference/taskade/#taskade.Task.__and__","title":"<code>__and__(other)</code>","text":"<p>Binary and operator for the task or a tuple of tasks This allows for the syntax task_a &amp; task_b when defining dependencies for another graph</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[Task, Tuple[Task, ...]]</code> <p>the task being <code>anded</code> with this task</p> required <p>Returns:</p> Type Description <code>Tuple[Task, ...]</code> <p>a tuple of this task and the one being added</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __and__(self: Task, other: Union[Task, Tuple[Task, ...]]) -&gt; Tuple[Task, ...]:\n    \"\"\"\n    Binary and operator for the task or a tuple of tasks\n    This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n    :param other: the task being `anded` with this task\n    :return: a tuple of this task and the one being added\n    \"\"\"\n    return (self, other) if isinstance(other, Task) else (self, *other)\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Executes the function within the task</p> <p>Returns:</p> Type Description <code>Union[_T, Awaitable[_T]]</code> <p>the results of the execution, if the function is async this will return the awaitable</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; Union[_T, Awaitable[_T]]:\n    \"\"\"\n    Executes the function within the task\n\n    :return: the results of the execution, if the function is async this will return the awaitable\n    \"\"\"\n    return self.func(*args, **kwargs)\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)</p> <p>Returns:</p> Type Description <code>int</code> <p>the hash for the task, which is a hash of the name</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __hash__(self: Task) -&gt; int:\n    \"\"\"\n    Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)\n\n    :return: the hash for the task, which is a hash of the name\n    \"\"\"\n    return hash(self.name)\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.__init__","title":"<code>__init__(func, dependencies=None, output_names=None, *, pre_call=None, post_call=None, init_kwargs=None, name=None, _graph=None)</code>","text":"<p>Initialize a Task object.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Union[Any, Awaitable[Any]]]</code> <p>The function that the task is wrapping</p> required <code>dependencies</code> <code>Optional[Union[Task, Tuple[Task, ...]]]</code> <p>The dependencies of the task, defaults to None</p> <code>None</code> <code>output_names</code> <code>Optional[Tuple[str, ...]]</code> <p>The names of the outputs of the task, defaults to None</p> <code>None</code> <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>The function to call with the results of the dependencies for this task, defaults to None</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>The function to call with the output of this task, defaults to None</p> <code>None</code> <code>init_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The optional initialization arguments for the task if not provided all input arguments will be provided by the dependency results, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>The optional name for this task, defaults to None</p> <code>None</code> <code>_graph</code> <code>Optional[Graph]</code> <p>The optional graph for this task, defaults to None</p> <code>None</code> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __init__(\n    self,\n    func: Callable[..., Union[Any, Awaitable[Any]]],\n    dependencies: Optional[Union[Task, Tuple[Task, ...]]] = None,\n    output_names: Optional[Tuple[str, ...]] = None,\n    *,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    init_kwargs: Optional[Dict[str, Any]] = None,\n    name: Optional[str] = None,\n    _graph: Optional[Graph] = None,\n):\n    \"\"\"\n    Initialize a Task object.\n\n    :param func: The function that the task is wrapping\n    :param dependencies: The dependencies of the task, defaults to None\n    :param output_names: The names of the outputs of the task, defaults to None\n    :param pre_call: The function to call with the results of the dependencies for this task, defaults to None\n    :param post_call: The function to call with the output of this task, defaults to None\n    :param init_kwargs: The optional initialization arguments for the task if not provided all input arguments will\n    be provided by the dependency results, defaults to None\n    :param name: The optional name for this task, defaults to None\n    :param _graph: The optional graph for this task, defaults to None\n    \"\"\"\n    self.func = func\n    self.output_names: Tuple[str, ...] = output_names if output_names is not None else ()\n    self.pre_call = pre_call\n    self.post_call = post_call\n    self.init_kwargs = init_kwargs\n    self.name = name if name is not None else str(uuid4())\n    self._graph = _graph\n\n    if dependencies is None:\n        self.dependencies = ()\n    elif isinstance(dependencies, Task):\n        self.dependencies = (dependencies,)\n    else:\n        self.dependencies = cast(Tuple[Task, ...], dependencies)\n\n    if len(self.dependencies) &gt; 0:\n        for dependent_task in self.dependencies:\n            self._set_graph(dependent_task)\n    elif self._graph is not None:  # For task graphs where no dependencies are provided\n        cast(Graph, self.graph) + self\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Binary rand operator for the task or a tuple of tasks This allows for the syntax task_a &amp; task_b when defining dependencies for another graph</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Task</code> <p>the task being <code>anded</code> with this task</p> required <p>Returns:</p> Type Description <code>Tuple[Task, ...]</code> <p>a tuple of this task and the one being added</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __rand__(self: Task, other: Task) -&gt; Tuple[Task, ...]:\n    \"\"\"\n    Binary rand operator for the task or a tuple of tasks\n    This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n    :param other: the task being `anded` with this task\n    :return: a tuple of this task and the one being added\n    \"\"\"\n    return (other, self) if isinstance(other, Task) else (*other, self)\n</code></pre>"},{"location":"reference/taskade/#taskade.Task.from_dict","title":"<code>from_dict(task_dict, func_map=None)</code>  <code>classmethod</code>","text":"<p>Create a task from a dictionary</p> <p>Parameters:</p> Name Type Description Default <code>task_dict</code> <code>Dict[str, Any]</code> <p>the dictionary of the task</p> required <code>func_map</code> <code>Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]]</code> <p>the mapping of the function names to the functions</p> <code>None</code> <p>Returns:</p> Type Description <code>Task</code> <p>the task object</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls: Type[Task],\n    task_dict: Dict[str, Any],\n    func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n) -&gt; Task:\n    \"\"\"\n    Create a task from a dictionary\n\n    :param task_dict: the dictionary of the task\n    :param func_map: the mapping of the function names to the functions\n    :return: the task object\n    \"\"\"\n    func = task_dict.pop(\"func\")\n    if func_map and func in func_map:\n        task = cls(func_map[func], **task_dict)\n    else:\n        # Attempt to import the function dynamically\n        module_name, func_name = func.rsplit(\".\", 1)\n        module = import_module(module_name)\n        # Check type of func to ensure it is a callable\n        func = getattr(module, func_name)\n        if not isinstance(func, Callable):\n            raise ValueError(f\"Function {func_name} in module {module_name} is not callable.\")\n        func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n        task = cls(func, **task_dict)\n    task_dict[\"func\"] = func\n    return task\n</code></pre>"},{"location":"reference/taskade/#taskade.aexecute_graph","title":"<code>aexecute_graph(graph, pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None)</code>  <code>async</code>","text":"<p>Asynchronously execute the graph</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>graph to execute</p> required <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>tasks_semaphore</code> <code>Optional[Semaphore]</code> <p>the semaphore to control the number of tasks running concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>GraphResults</code> <p>the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>async def aexecute_graph(\n    graph: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n) -&gt; GraphResults:\n    \"\"\"\n    Asynchronously execute the graph\n\n    :param graph: graph to execute\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param tasks_semaphore: the semaphore to control the number of tasks running concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: the result of the graph execution\n    \"\"\"\n    if graph._results:\n        return graph._results\n    graph.low_level_graph.prepare()\n    result_queue = asyncio.Queue()\n    results: Dict[Task, Union[Any, Tuple[Any, ...]]] = {}\n    while graph.low_level_graph.is_active():\n        available_tasks = graph.low_level_graph.get_ready()\n        eligible_tasks = _get_eligble_tasks(available_tasks, results) if not raise_immediately else available_tasks\n        for available_task in eligible_tasks:\n            available_task = cast(Task, available_task)\n            if not available_task.is_async:\n\n                @wraps(available_task.func)\n                async def async_wrapper(*args, **kwargs) -&gt; Any:\n                    return available_task.func(*args, **kwargs)\n\n                executing_func = async_wrapper\n            else:\n                executing_func = cast(Callable[..., Awaitable[Any]], available_task.func)\n            call_args, call_kwargs = _get_args_from_dependencies(available_task.dependencies, results)\n            task_pre_call = available_task.pre_call if available_task.pre_call else pre_call\n            call_kwargs = _execute_pre_call(task_pre_call, available_task, *call_args, **call_kwargs)\n            if available_task.init_kwargs:\n                call_kwargs.update(available_task.init_kwargs)\n            # TODO: Look into using asyncio.wait instead of the queue, assumption is possible speed improvement?\n            asyncio.create_task(\n                _aproducer(available_task, executing_func(*call_args, **call_kwargs), result_queue, tasks_semaphore)\n            )\n        task, result = await _aconsumer(result_queue, raise_immediately)\n        _execute_post_call(post_call, task, result, results)\n        graph.low_level_graph.done(task)\n        results[task] = result\n    graph._results = GraphResults({task.name: result for task, result in results.items()})\n    return graph._results\n</code></pre>"},{"location":"reference/taskade/#taskade.execute_graph","title":"<code>execute_graph(graph, pre_call=None, post_call=None, raise_immediately=True, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<p>Execute the graph with optional concurrency</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>graph to execute</p> required <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precedence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>concurrency_pool</code> <code>Union[ThreadPoolExecutor, ProcessPoolExecutor, Type[ThreadPoolExecutor], Type[ProcessPoolExecutor]]</code> <p>pool for executing a graph concurrently, this pool will be used for executing the individual tasks, can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThreadPoolExecutor type</p> <code>ThreadPoolExecutor</code> <code>n_jobs</code> <code>Optional[int]</code> <p>optional number of jobs for executing a graph concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>GraphResults</code> <p>the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def execute_graph(\n    graph: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    concurrency_pool: Union[\n        ThreadPoolExecutor, ProcessPoolExecutor, Type[ThreadPoolExecutor], Type[ProcessPoolExecutor]\n    ] = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; GraphResults:\n    \"\"\"\n    Execute the graph with optional concurrency\n\n    :param graph: graph to execute\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precedence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param concurrency_pool: pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThreadPoolExecutor type\n    :param n_jobs: optional number of jobs for executing a graph concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: the result of the graph execution\n    \"\"\"\n    if graph._results:\n        return graph._results\n    if isinstance(concurrency_pool, (ThreadPoolExecutor, ProcessPoolExecutor)):\n        result = _concurrent_execute_graph(graph, concurrency_pool, pre_call, post_call, raise_immediately)\n    elif n_jobs and concurrency_pool in (ThreadPoolExecutor, ProcessPoolExecutor):\n        with concurrency_pool(max_workers=n_jobs) as pool:\n            result = _concurrent_execute_graph(graph, pool, pre_call, post_call, raise_immediately)\n    else:\n        result = _sync_execute_graph(graph, pre_call, post_call, raise_immediately)\n    graph._results = result\n    return graph._results\n</code></pre>"},{"location":"reference/taskade/#taskade.get_graph","title":"<code>get_graph(graph_name)</code>","text":"<p>Retrieve a graph by name from the global graph dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to retrieve</p> required <p>Returns:</p> Type Description <code>Optional[Graph]</code> <p>The retrieved Graph object or None if not found</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def get_graph(graph_name: str) -&gt; Optional[Graph]:\n    \"\"\"\n    Retrieve a graph by name from the global graph dictionary.\n\n    :param graph_name: The name of the graph to retrieve\n    :return: The retrieved Graph object or None if not found\n    \"\"\"\n    return _get_graph().get(graph_name)\n</code></pre>"},{"location":"reference/taskade/#taskade.task","title":"<code>task(graph_name, *, dependencies=(), output_names=(), pre_call=None, post_call=None, name=None, init_kwargs=None)</code>","text":"<p>Decorator to create a Task with its dependencies and associate it with a named graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to associate the task with</p> required <code>dependencies</code> <code>Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]]</code> <p>A tuple of Task objects or names of tasks within the same graph that this task depends on</p> <code>()</code> <code>output_names</code> <code>Tuple[str, ...]</code> <p>A tuple of output names for the task</p> <code>()</code> <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>An optional function to be called before the task execution, defaults to None</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>An optional function to be called after the task execution, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>An optional name for the task, defaults to None</p> <code>None</code> <code>init_kwargs</code> <code>Optional[Dict[str, _T]]</code> <p>Optional kwargs to use for executing the task, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[..., Task]</code> <p>A decorator function that wraps the task function</p> Source code in <code>src/taskade/_decorator.py</code> <pre><code>def task(\n    graph_name: str,\n    *,\n    dependencies: Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]] = (),\n    output_names: Tuple[str, ...] = (),\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    name: Optional[str] = None,\n    init_kwargs: Optional[Dict[str, _T]] = None,\n) -&gt; Callable[..., Task]:\n    \"\"\"\n    Decorator to create a Task with its dependencies and associate it with a named graph.\n\n    :param graph_name: The name of the graph to associate the task with\n    :param dependencies: A tuple of Task objects or names of tasks within the same graph that this task depends on\n    :param output_names: A tuple of output names for the task\n    :param pre_call: An optional function to be called before the task execution, defaults to None\n    :param post_call: An optional function to be called after the task execution, defaults to None\n    :param name: An optional name for the task, defaults to None\n    :param init_kwargs: Optional kwargs to use for executing the task, defaults to None\n    :return: A decorator function that wraps the task function\n    \"\"\"\n\n    def decorator(\n        func: Union[Dict[str, Dict[str, Task]], Union[Task, Callable[..., Union[_T, Awaitable[_T]]]]],\n        name: Optional[str] = name,\n        dependencies: Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]] = dependencies,\n    ) -&gt; Task:\n        \"\"\"\n        Inner decorator function that wraps the task function.\n\n        :param func: The function to be wrapped as a task\n        :param name: An optional name for the task\n        :param dependencies: A tuple of Task objects or names of tasks within the same graph that this task depends on\n        :return: The wrapped task function\n        \"\"\"\n        # Allow for multiple uses of the decorator on the same function\n        if isinstance(func, Task):\n            func = func.func\n        func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n        name = name if name else func.__name__\n        graph = __retrieve_or_create_graph(graph_name)\n\n        task_instance = Task(\n            func=func,\n            dependencies=__map_dependencies(graph_name, name, dependencies),\n            _graph=graph,\n            output_names=output_names,\n            pre_call=pre_call,\n            post_call=post_call,\n            name=name,\n            init_kwargs=init_kwargs,\n        )\n\n        # Add the task to the graph\n        graph += task_instance\n        return task_instance\n\n    return decorator\n</code></pre>"},{"location":"reference/taskade/_decorator/","title":"_decorator","text":""},{"location":"reference/taskade/_decorator/#taskade._decorator.__map_dependencies","title":"<code>__map_dependencies(graph_name, task_name, dependencies)</code>","text":"<p>Map dependencies to Task objects, needed for multiple decorators on the same function as dependencies will use the task name instead of the task object directly.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>name of the graph</p> required <code>task_name</code> <code>Optional[str]</code> <p>name of the task</p> required <code>dependencies</code> <code>Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]]</code> <p>dependencies of the task, can be an individual element or a tuple of elements where the elements are either Task objects or names of tasks within the same graph</p> required <p>Returns:</p> Type Description <code>Tuple[Task, ...]</code> <p>tuple of Task objects</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the dependency is not found in the graph</p> Source code in <code>src/taskade/_decorator.py</code> <pre><code>def __map_dependencies(\n    graph_name: str,\n    task_name: Optional[str],\n    dependencies: Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]],\n) -&gt; Tuple[Task, ...]:\n    \"\"\"\n    Map dependencies to Task objects, needed for multiple decorators on the same function\n    as dependencies will use the task name instead of the task object directly.\n\n    :param graph_name: name of the graph\n    :param task_name: name of the task\n    :param dependencies: dependencies of the task, can be an individual element or a tuple of elements where the elements are either Task objects or names of tasks within the same graph\n    :raises ValueError: if the dependency is not found in the graph\n    :return: tuple of Task objects\n    \"\"\"\n    if isinstance(dependencies, str):\n        dependencies = (dependencies,)\n    if isinstance(dependencies, tuple) and len(dependencies) &gt; 0 and isinstance(dependencies[0], str):\n        dependencies = cast(Tuple[str, ...], dependencies)\n        mapped_dependencies = []\n        for dependency in dependencies:\n            try:\n                mapped_dependencies.append(_get_graph()[graph_name][dependency])\n            except KeyError:\n                raise ValueError(\n                    f\"Task {task_name} within graph {graph_name} has a dependency {dependency} on a function that has not been decorated or names for decorated functions are misaligned to their dependency usage.\"\n                )\n        dependencies = tuple(mapped_dependencies)\n    return cast(Tuple[Task, ...], dependencies)\n</code></pre>"},{"location":"reference/taskade/_decorator/#taskade._decorator.__retrieve_or_create_graph","title":"<code>__retrieve_or_create_graph(graph_name)</code>","text":"<p>Retrieve a graph by name from the global graph dictionary or create a new graph if not found.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to retrieve or create</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>The retrieved or created Graph object</p> Source code in <code>src/taskade/_decorator.py</code> <pre><code>def __retrieve_or_create_graph(graph_name: str) -&gt; Graph:\n    \"\"\"\n    Retrieve a graph by name from the global graph dictionary or create a new graph if not found.\n\n    :param graph_name: The name of the graph to retrieve or create\n    :return: The retrieved or created Graph object\n    \"\"\"\n    graph = _get_graph().get(graph_name)\n    if graph is None:\n        graph = Graph(name=graph_name)\n        _get_graph()[graph_name] = graph\n    return graph\n</code></pre>"},{"location":"reference/taskade/_decorator/#taskade._decorator.task","title":"<code>task(graph_name, *, dependencies=(), output_names=(), pre_call=None, post_call=None, name=None, init_kwargs=None)</code>","text":"<p>Decorator to create a Task with its dependencies and associate it with a named graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to associate the task with</p> required <code>dependencies</code> <code>Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]]</code> <p>A tuple of Task objects or names of tasks within the same graph that this task depends on</p> <code>()</code> <code>output_names</code> <code>Tuple[str, ...]</code> <p>A tuple of output names for the task</p> <code>()</code> <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>An optional function to be called before the task execution, defaults to None</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>An optional function to be called after the task execution, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>An optional name for the task, defaults to None</p> <code>None</code> <code>init_kwargs</code> <code>Optional[Dict[str, _T]]</code> <p>Optional kwargs to use for executing the task, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[..., Task]</code> <p>A decorator function that wraps the task function</p> Source code in <code>src/taskade/_decorator.py</code> <pre><code>def task(\n    graph_name: str,\n    *,\n    dependencies: Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]] = (),\n    output_names: Tuple[str, ...] = (),\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    name: Optional[str] = None,\n    init_kwargs: Optional[Dict[str, _T]] = None,\n) -&gt; Callable[..., Task]:\n    \"\"\"\n    Decorator to create a Task with its dependencies and associate it with a named graph.\n\n    :param graph_name: The name of the graph to associate the task with\n    :param dependencies: A tuple of Task objects or names of tasks within the same graph that this task depends on\n    :param output_names: A tuple of output names for the task\n    :param pre_call: An optional function to be called before the task execution, defaults to None\n    :param post_call: An optional function to be called after the task execution, defaults to None\n    :param name: An optional name for the task, defaults to None\n    :param init_kwargs: Optional kwargs to use for executing the task, defaults to None\n    :return: A decorator function that wraps the task function\n    \"\"\"\n\n    def decorator(\n        func: Union[Dict[str, Dict[str, Task]], Union[Task, Callable[..., Union[_T, Awaitable[_T]]]]],\n        name: Optional[str] = name,\n        dependencies: Union[Union[Tuple[str, ...], str], Union[Task, Tuple[Task, ...]]] = dependencies,\n    ) -&gt; Task:\n        \"\"\"\n        Inner decorator function that wraps the task function.\n\n        :param func: The function to be wrapped as a task\n        :param name: An optional name for the task\n        :param dependencies: A tuple of Task objects or names of tasks within the same graph that this task depends on\n        :return: The wrapped task function\n        \"\"\"\n        # Allow for multiple uses of the decorator on the same function\n        if isinstance(func, Task):\n            func = func.func\n        func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n        name = name if name else func.__name__\n        graph = __retrieve_or_create_graph(graph_name)\n\n        task_instance = Task(\n            func=func,\n            dependencies=__map_dependencies(graph_name, name, dependencies),\n            _graph=graph,\n            output_names=output_names,\n            pre_call=pre_call,\n            post_call=post_call,\n            name=name,\n            init_kwargs=init_kwargs,\n        )\n\n        # Add the task to the graph\n        graph += task_instance\n        return task_instance\n\n    return decorator\n</code></pre>"},{"location":"reference/taskade/_exceptions/","title":"_exceptions","text":""},{"location":"reference/taskade/_exceptions/#taskade._exceptions.FailedDependencyError","title":"<code>FailedDependencyError</code>","text":"<p>               Bases: <code>TaskadeError</code></p> <p>Error for when all available tasks have at least one failed dependency.</p> Source code in <code>src/taskade/_exceptions.py</code> <pre><code>class FailedDependencyError(TaskadeError):\n    \"\"\"Error for when all available tasks have at least one failed dependency.\"\"\"\n\n    def __init__(self: FailedDependencyError, message: str, partial_results: Dict[Any, _T]):\n        \"\"\"\n        Initialize the FailedDependencyError.\n\n        :param message: the message to display\n        :param partial_results: the partial results of the graph execution\n        \"\"\"\n        super().__init__(message)\n        self.partial_results = partial_results\n</code></pre>"},{"location":"reference/taskade/_exceptions/#taskade._exceptions.FailedDependencyError.__init__","title":"<code>__init__(message, partial_results)</code>","text":"<p>Initialize the FailedDependencyError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>the message to display</p> required <code>partial_results</code> <code>Dict[Any, _T]</code> <p>the partial results of the graph execution</p> required Source code in <code>src/taskade/_exceptions.py</code> <pre><code>def __init__(self: FailedDependencyError, message: str, partial_results: Dict[Any, _T]):\n    \"\"\"\n    Initialize the FailedDependencyError.\n\n    :param message: the message to display\n    :param partial_results: the partial results of the graph execution\n    \"\"\"\n    super().__init__(message)\n    self.partial_results = partial_results\n</code></pre>"},{"location":"reference/taskade/_exceptions/#taskade._exceptions.TaskadeError","title":"<code>TaskadeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for Taskade exceptions.</p> Source code in <code>src/taskade/_exceptions.py</code> <pre><code>class TaskadeError(Exception):\n    \"\"\"Base class for Taskade exceptions.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/taskade/_execution/","title":"_execution","text":""},{"location":"reference/taskade/_execution/#taskade._execution.log","title":"<code>log = getLogger(__name__)</code>  <code>module-attribute</code>","text":"<p>The logger for the module</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph","title":"<code>Graph</code>","text":"<p>The graph object, tying together multiple tasks together for execution of a DAG</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class Graph:\n    \"\"\"The graph object, tying together multiple tasks together for execution of a DAG\"\"\"\n\n    def __init__(\n        self,\n        tasks: Optional[Tuple[Task, ...]] = None,\n        name: Optional[str] = None,\n        initial_capacity: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initializer for the graph\n\n        :param tasks: tuple of tasks tied to this graph, defaults to None\n        :param name: the identifier for the graph, defaults to None\n        :param initial_capactiy: the initial capacity of the graph, only applicable to cgraphlib, defaults to None\n        \"\"\"\n        super().__init__()\n        self._results: Optional[GraphResults] = None\n        self.__graph_add = self.__c_graph_add if __cgraphlib__ else self.__std_graph_add\n        if initial_capacity:\n            if __cgraphlib__:\n                self.__graph = TopologicalSorter(initial_capacity)  # type: ignore fix for cgraphlib\n            else:\n                log.warning(\"Initial capacity is only applicable to cgraphlib, ignoring.\")\n                self.__graph = TopologicalSorter()\n        else:\n            self.__graph = TopologicalSorter()\n        self.name = name\n        self.__is_async = False\n        self._node_to_dependencies: Dict[Task, Tuple[Task, ...]] = {}\n        if tasks:\n            for task in tasks:\n                self._node_to_dependencies[task] = task.dependencies\n                self.__graph_add(task)\n                if not self.__is_async:\n                    self.__is_async = task.is_async\n        if self.name:\n            _get_graph()[self.name] = self\n\n    def __del__(self):\n        \"\"\"\n        Destructor for the graph, removes the graph from the global graph dictionary\n        \"\"\"\n        try:\n            delete_graph(self.name)\n        except KeyError:\n            pass\n        for task in self._node_to_dependencies:\n            task._graph = None  # Remove the reference to the graph\n\n    def __c_graph_add(self: Graph, task: Task) -&gt; None:\n        \"\"\"\n        Adds a task to the graph when using cgraphlib\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        self.__graph.add(task, task.dependencies)\n\n    def __std_graph_add(self: Graph, task: Task) -&gt; None:\n        \"\"\"\n        Adds a task to the graph when using std graphlib\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        self.__graph.add(task, *task.dependencies)\n\n    def __getitem__(self, key: str) -&gt; Task:\n        \"\"\"\n        Gets the task by name in the graph\n\n        :param key: the name of the task to retrieve\n        :raises KeyError: raised if the task is not found in the graph\n        :return: the task object\n        \"\"\"\n        for task in self._node_to_dependencies:\n            if task.name == key:\n                return task\n        raise KeyError(f\"Task {key} not found in graph.\")\n\n    @classmethod\n    def from_list(\n        cls: Type[Graph],\n        graph_name: str,\n        tasks_list: List[Dict[str, str]],\n        func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n    ) -&gt; Graph:\n        \"\"\"\n        Create a graph from a list of tasks\n\n        :param cls: the class object of the graph\n        :param graph_name: the name of the graph to create\n        :param tasks_list: the list of tasks to add to the graph\n        :param func_map: optional mapping of function names to their function, defaults to None\n        :return: the graph object\n        \"\"\"\n        graph = cls(name=graph_name)\n        for task_dict in tasks_list:\n            graph += Task.from_dict(task_dict, func_map)\n        return graph\n\n    @property\n    def low_level_graph(self: Graph) -&gt; TopologicalSorter:\n        \"\"\"\n        The low level graph object\n\n        :return: the low level graph object\n        \"\"\"\n        return self.__graph\n\n    @property\n    def unsorted_graph(self: Graph) -&gt; Dict[Task, Tuple[Task, ...]]:\n        \"\"\"\n        The unsorted version of the graph\n\n        :return: the dictionary of task to its dependencies\n        \"\"\"\n        return self._node_to_dependencies\n\n    @property\n    def is_async(self: Graph) -&gt; bool:\n        \"\"\"\n        Indicates if the graph is async\n\n        :return: true if any node in the graph is async, otherwise false\n        \"\"\"\n        return self.__is_async\n\n    def __add__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n        \"\"\"\n        Addition operator\n\n        :param task: the task to add to the graph\n        :return: the graph itself\n        \"\"\"\n        if isinstance(tasks, Task):\n            tasks = (tasks,)\n        for task in tasks:\n            if not self.__is_async:\n                self.__is_async = task.is_async\n            if task._graph is not None:\n                if task.graph != self:\n                    raise ValueError(f\"Task {task.name} is already part of a different graph.\")\n            task._graph = self\n            self._node_to_dependencies[task] = task.dependencies\n            self.__graph_add(task)\n        return self\n\n    def __iadd__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n        \"\"\"\n        In place addition operator for adding a task to the graph\n\n        :param tasks: the task or tuple of tasks to add to the graph\n        :return: the graph itself\n        \"\"\"\n        return self + tasks\n\n    def execute(\n        self: Graph,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        raise_immediately: bool = True,\n        tasks_semaphore: Optional[asyncio.Semaphore] = None,\n        concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n        n_jobs: Optional[int] = None,\n    ) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n        \"\"\"\n        Executes the graph\n\n        :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n        :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n        :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n        if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n        :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n        :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n        can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n        :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n        :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n        :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n        \"\"\"\n        if self.is_async:\n            return aexecute_graph(self, pre_call, post_call, raise_immediately, tasks_semaphore)\n        else:\n            return execute_graph(self, pre_call, post_call, raise_immediately, concurrency_pool, n_jobs)\n\n    def __call__(\n        self: Graph,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        raise_immediately: bool = True,\n        tasks_semaphore: Optional[asyncio.Semaphore] = None,\n        concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n        n_jobs: Optional[int] = None,\n    ) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n        \"\"\"\n            Executes the graph\n            :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n            :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n            :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n            if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n            :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n            :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n        can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n        :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n            :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n            :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n        \"\"\"\n        return self.execute(pre_call, post_call, raise_immediately, tasks_semaphore, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.is_async","title":"<code>is_async: bool</code>  <code>property</code>","text":"<p>Indicates if the graph is async</p> <p>Returns:</p> Type Description <code>bool</code> <p>true if any node in the graph is async, otherwise false</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.low_level_graph","title":"<code>low_level_graph: TopologicalSorter</code>  <code>property</code>","text":"<p>The low level graph object</p> <p>Returns:</p> Type Description <code>TopologicalSorter</code> <p>the low level graph object</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.unsorted_graph","title":"<code>unsorted_graph: Dict[Task, Tuple[Task, ...]]</code>  <code>property</code>","text":"<p>The unsorted version of the graph</p> <p>Returns:</p> Type Description <code>Dict[Task, Tuple[Task, ...]]</code> <p>the dictionary of task to its dependencies</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__add__","title":"<code>__add__(tasks)</code>","text":"<p>Addition operator</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __add__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n    \"\"\"\n    Addition operator\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    if isinstance(tasks, Task):\n        tasks = (tasks,)\n    for task in tasks:\n        if not self.__is_async:\n            self.__is_async = task.is_async\n        if task._graph is not None:\n            if task.graph != self:\n                raise ValueError(f\"Task {task.name} is already part of a different graph.\")\n        task._graph = self\n        self._node_to_dependencies[task] = task.dependencies\n        self.__graph_add(task)\n    return self\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__c_graph_add","title":"<code>__c_graph_add(task)</code>","text":"<p>Adds a task to the graph when using cgraphlib</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>None</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __c_graph_add(self: Graph, task: Task) -&gt; None:\n    \"\"\"\n    Adds a task to the graph when using cgraphlib\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    self.__graph.add(task, task.dependencies)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__call__","title":"<code>__call__(pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<pre><code>Executes the graph\n:param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n:param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n:param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\nif False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n:param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n:param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n</code></pre> <p>can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type</p> <p>Parameters:</p> Name Type Description Default <code>n_jobs</code> <code>Optional[int]</code> <p>only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution</p> <code>None</code> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __call__(\n    self: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n    concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n    \"\"\"\n        Executes the graph\n        :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n        :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n        :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n        if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n        :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n        :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n    :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n        :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n        :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n    \"\"\"\n    return self.execute(pre_call, post_call, raise_immediately, tasks_semaphore, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__del__","title":"<code>__del__()</code>","text":"<p>Destructor for the graph, removes the graph from the global graph dictionary</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __del__(self):\n    \"\"\"\n    Destructor for the graph, removes the graph from the global graph dictionary\n    \"\"\"\n    try:\n        delete_graph(self.name)\n    except KeyError:\n        pass\n    for task in self._node_to_dependencies:\n        task._graph = None  # Remove the reference to the graph\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Gets the task by name in the graph</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>the name of the task to retrieve</p> required <p>Returns:</p> Type Description <code>Task</code> <p>the task object</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>raised if the task is not found in the graph</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Task:\n    \"\"\"\n    Gets the task by name in the graph\n\n    :param key: the name of the task to retrieve\n    :raises KeyError: raised if the task is not found in the graph\n    :return: the task object\n    \"\"\"\n    for task in self._node_to_dependencies:\n        if task.name == key:\n            return task\n    raise KeyError(f\"Task {key} not found in graph.\")\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__iadd__","title":"<code>__iadd__(tasks)</code>","text":"<p>In place addition operator for adding a task to the graph</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Union[Task, Tuple[Task, ...]]</code> <p>the task or tuple of tasks to add to the graph</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __iadd__(self: Graph, tasks: Union[Task, Tuple[Task, ...]]) -&gt; Graph:\n    \"\"\"\n    In place addition operator for adding a task to the graph\n\n    :param tasks: the task or tuple of tasks to add to the graph\n    :return: the graph itself\n    \"\"\"\n    return self + tasks\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__init__","title":"<code>__init__(tasks=None, name=None, initial_capacity=None)</code>","text":"<p>Initializer for the graph</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tuple[Task, ...]]</code> <p>tuple of tasks tied to this graph, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>the identifier for the graph, defaults to None</p> <code>None</code> <code>initial_capactiy</code> <p>the initial capacity of the graph, only applicable to cgraphlib, defaults to None</p> required Source code in <code>src/taskade/_execution.py</code> <pre><code>def __init__(\n    self,\n    tasks: Optional[Tuple[Task, ...]] = None,\n    name: Optional[str] = None,\n    initial_capacity: Optional[int] = None,\n) -&gt; None:\n    \"\"\"\n    Initializer for the graph\n\n    :param tasks: tuple of tasks tied to this graph, defaults to None\n    :param name: the identifier for the graph, defaults to None\n    :param initial_capactiy: the initial capacity of the graph, only applicable to cgraphlib, defaults to None\n    \"\"\"\n    super().__init__()\n    self._results: Optional[GraphResults] = None\n    self.__graph_add = self.__c_graph_add if __cgraphlib__ else self.__std_graph_add\n    if initial_capacity:\n        if __cgraphlib__:\n            self.__graph = TopologicalSorter(initial_capacity)  # type: ignore fix for cgraphlib\n        else:\n            log.warning(\"Initial capacity is only applicable to cgraphlib, ignoring.\")\n            self.__graph = TopologicalSorter()\n    else:\n        self.__graph = TopologicalSorter()\n    self.name = name\n    self.__is_async = False\n    self._node_to_dependencies: Dict[Task, Tuple[Task, ...]] = {}\n    if tasks:\n        for task in tasks:\n            self._node_to_dependencies[task] = task.dependencies\n            self.__graph_add(task)\n            if not self.__is_async:\n                self.__is_async = task.is_async\n    if self.name:\n        _get_graph()[self.name] = self\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.__std_graph_add","title":"<code>__std_graph_add(task)</code>","text":"<p>Adds a task to the graph when using std graphlib</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Task</code> <p>the task to add to the graph</p> required <p>Returns:</p> Type Description <code>None</code> <p>the graph itself</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __std_graph_add(self: Graph, task: Task) -&gt; None:\n    \"\"\"\n    Adds a task to the graph when using std graphlib\n\n    :param task: the task to add to the graph\n    :return: the graph itself\n    \"\"\"\n    self.__graph.add(task, *task.dependencies)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.execute","title":"<code>execute(pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<p>Executes the graph</p> <p>Parameters:</p> Name Type Description Default <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>tasks_semaphore</code> <code>Optional[Semaphore]</code> <p>only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None</p> <code>None</code> <code>concurrency_pool</code> <code>PoolExecutor</code> <p>only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks, can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type</p> <code>ThreadPoolExecutor</code> <code>n_jobs</code> <code>Optional[int]</code> <p>only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GraphResults, Awaitable[GraphResults]]</code> <p>if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def execute(\n    self: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n    concurrency_pool: PoolExecutor = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; Union[GraphResults, Awaitable[GraphResults]]:\n    \"\"\"\n    Executes the graph\n\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param tasks_semaphore: only applies to async execution, the semaphore to control the number of tasks running concurrently, defaults to None\n    :param concurrency_pool: only applies to non-async execution, pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThredPoolExecutor type\n    :param n_jobs: only applies to non-async execution, optional number of jobs for executing a graph concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: if the graph is async this will return the awaitable, otherwise this will return the result of the graph execution\n    \"\"\"\n    if self.is_async:\n        return aexecute_graph(self, pre_call, post_call, raise_immediately, tasks_semaphore)\n    else:\n        return execute_graph(self, pre_call, post_call, raise_immediately, concurrency_pool, n_jobs)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Graph.from_list","title":"<code>from_list(graph_name, tasks_list, func_map=None)</code>  <code>classmethod</code>","text":"<p>Create a graph from a list of tasks</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Graph]</code> <p>the class object of the graph</p> required <code>graph_name</code> <code>str</code> <p>the name of the graph to create</p> required <code>tasks_list</code> <code>List[Dict[str, str]]</code> <p>the list of tasks to add to the graph</p> required <code>func_map</code> <code>Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]]</code> <p>optional mapping of function names to their function, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>Graph</code> <p>the graph object</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>@classmethod\ndef from_list(\n    cls: Type[Graph],\n    graph_name: str,\n    tasks_list: List[Dict[str, str]],\n    func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n) -&gt; Graph:\n    \"\"\"\n    Create a graph from a list of tasks\n\n    :param cls: the class object of the graph\n    :param graph_name: the name of the graph to create\n    :param tasks_list: the list of tasks to add to the graph\n    :param func_map: optional mapping of function names to their function, defaults to None\n    :return: the graph object\n    \"\"\"\n    graph = cls(name=graph_name)\n    for task_dict in tasks_list:\n        graph += Task.from_dict(task_dict, func_map)\n    return graph\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.GraphResults","title":"<code>GraphResults</code>","text":"<p>               Bases: <code>UserDict</code></p> <p>Results of a graph execution</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class GraphResults(UserDict):\n    \"\"\"Results of a graph execution\"\"\"\n\n    def __getitem__(self, key: Task | int | str) -&gt; _T:\n        \"\"\"\n        Get the result of a task by its name or hash.\n        This allows for retrieval of task results by either the name or the task object itself\n\n        :param key: the task, task name name or hash\n        :return: the result of the task\n        \"\"\"\n        if isinstance(key, Task):\n            key = cast(str, key.name)\n        return super().__getitem__(key)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.GraphResults.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get the result of a task by its name or hash. This allows for retrieval of task results by either the name or the task object itself</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Task | int | str</code> <p>the task, task name name or hash</p> required <p>Returns:</p> Type Description <code>_T</code> <p>the result of the task</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __getitem__(self, key: Task | int | str) -&gt; _T:\n    \"\"\"\n    Get the result of a task by its name or hash.\n    This allows for retrieval of task results by either the name or the task object itself\n\n    :param key: the task, task name name or hash\n    :return: the result of the task\n    \"\"\"\n    if isinstance(key, Task):\n        key = cast(str, key.name)\n    return super().__getitem__(key)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.PostCallProtocol","title":"<code>PostCallProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the post_call function</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class PostCallProtocol(Protocol):\n    \"\"\"Protocol for the post_call function\"\"\"\n\n    def __call__(self, result: _T, *args: Tuple[_T, ...]) -&gt; None: ...  # pragma: no cover\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.PreCallProtocol","title":"<code>PreCallProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the pre_call function</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class PreCallProtocol(Protocol):\n    \"\"\"Protocol for the pre_call function\"\"\"\n\n    def __call__(\n        self, task: Task, *args: Tuple[_T, ...], **kwargs: Dict[str, _T]\n    ) -&gt; Optional[Dict[str, _T]]: ...  # pragma: no cover\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task","title":"<code>Task</code>","text":"<p>The task object, wrapping a function and its dependencies</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>class Task:\n    \"\"\"The task object, wrapping a function and its dependencies\"\"\"\n\n    def __init__(\n        self,\n        func: Callable[..., Union[Any, Awaitable[Any]]],\n        dependencies: Optional[Union[Task, Tuple[Task, ...]]] = None,\n        output_names: Optional[Tuple[str, ...]] = None,\n        *,\n        pre_call: Optional[PreCallProtocol] = None,\n        post_call: Optional[PostCallProtocol] = None,\n        init_kwargs: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n        _graph: Optional[Graph] = None,\n    ):\n        \"\"\"\n        Initialize a Task object.\n\n        :param func: The function that the task is wrapping\n        :param dependencies: The dependencies of the task, defaults to None\n        :param output_names: The names of the outputs of the task, defaults to None\n        :param pre_call: The function to call with the results of the dependencies for this task, defaults to None\n        :param post_call: The function to call with the output of this task, defaults to None\n        :param init_kwargs: The optional initialization arguments for the task if not provided all input arguments will\n        be provided by the dependency results, defaults to None\n        :param name: The optional name for this task, defaults to None\n        :param _graph: The optional graph for this task, defaults to None\n        \"\"\"\n        self.func = func\n        self.output_names: Tuple[str, ...] = output_names if output_names is not None else ()\n        self.pre_call = pre_call\n        self.post_call = post_call\n        self.init_kwargs = init_kwargs\n        self.name = name if name is not None else str(uuid4())\n        self._graph = _graph\n\n        if dependencies is None:\n            self.dependencies = ()\n        elif isinstance(dependencies, Task):\n            self.dependencies = (dependencies,)\n        else:\n            self.dependencies = cast(Tuple[Task, ...], dependencies)\n\n        if len(self.dependencies) &gt; 0:\n            for dependent_task in self.dependencies:\n                self._set_graph(dependent_task)\n        elif self._graph is not None:  # For task graphs where no dependencies are provided\n            cast(Graph, self.graph) + self\n\n    def __call__(self, *args, **kwargs) -&gt; Union[_T, Awaitable[_T]]:\n        \"\"\"\n        Executes the function within the task\n\n        :return: the results of the execution, if the function is async this will return the awaitable\n        \"\"\"\n        return self.func(*args, **kwargs)\n\n    @classmethod\n    def from_dict(\n        cls: Type[Task],\n        task_dict: Dict[str, Any],\n        func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n    ) -&gt; Task:\n        \"\"\"\n        Create a task from a dictionary\n\n        :param task_dict: the dictionary of the task\n        :param func_map: the mapping of the function names to the functions\n        :return: the task object\n        \"\"\"\n        func = task_dict.pop(\"func\")\n        if func_map and func in func_map:\n            task = cls(func_map[func], **task_dict)\n        else:\n            # Attempt to import the function dynamically\n            module_name, func_name = func.rsplit(\".\", 1)\n            module = import_module(module_name)\n            # Check type of func to ensure it is a callable\n            func = getattr(module, func_name)\n            if not isinstance(func, Callable):\n                raise ValueError(f\"Function {func_name} in module {module_name} is not callable.\")\n            func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n            task = cls(func, **task_dict)\n        task_dict[\"func\"] = func\n        return task\n\n    def _set_graph(self: Task, other: Task) -&gt; None:\n        \"\"\"\n        Ensures that this task and another task are tied to the same graph,\n\n        :param other: the other task tied to this task\n        :raises ValueError: if both tasks have a graph and they are not the same graph\n        \"\"\"\n        if self._graph is None:\n            graph = other.graph\n            if graph is not None:\n                self._graph = graph\n                graph + self\n            else:\n                self._graph = Graph((self, other))\n                other._graph = self._graph\n        else:\n            if other.graph is not None and self.graph != other.graph:\n                raise ValueError(f\"Task {self.name} and Task {other.name} are in different graphs.\")\n            graph = cast(Graph, self.graph)\n            graph + other\n\n    @property\n    def is_async(self: Task) -&gt; bool:\n        \"\"\"\n        Indicates if the task is async\n\n        :return: true if the task is async, false otherwise\n        \"\"\"\n        return asyncio.iscoroutinefunction(self.func)\n\n    @property\n    def graph(self: Task) -&gt; Optional[Graph]:\n        \"\"\"\n        The underlying graph for the task\n\n        :return: the graph for the task, this will be None if this task is not part of a graph\n        \"\"\"\n        return self._graph\n\n    def __hash__(self: Task) -&gt; int:\n        \"\"\"\n        Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)\n\n        :return: the hash for the task, which is a hash of the name\n        \"\"\"\n        return hash(self.name)\n\n    def __and__(self: Task, other: Union[Task, Tuple[Task, ...]]) -&gt; Tuple[Task, ...]:\n        \"\"\"\n        Binary and operator for the task or a tuple of tasks\n        This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n        :param other: the task being `anded` with this task\n        :return: a tuple of this task and the one being added\n        \"\"\"\n        return (self, other) if isinstance(other, Task) else (self, *other)\n\n    def __rand__(self: Task, other: Task) -&gt; Tuple[Task, ...]:\n        \"\"\"\n        Binary rand operator for the task or a tuple of tasks\n        This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n        :param other: the task being `anded` with this task\n        :return: a tuple of this task and the one being added\n        \"\"\"\n        return (other, self) if isinstance(other, Task) else (*other, self)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.graph","title":"<code>graph: Optional[Graph]</code>  <code>property</code>","text":"<p>The underlying graph for the task</p> <p>Returns:</p> Type Description <code>Optional[Graph]</code> <p>the graph for the task, this will be None if this task is not part of a graph</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.is_async","title":"<code>is_async: bool</code>  <code>property</code>","text":"<p>Indicates if the task is async</p> <p>Returns:</p> Type Description <code>bool</code> <p>true if the task is async, false otherwise</p>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.__and__","title":"<code>__and__(other)</code>","text":"<p>Binary and operator for the task or a tuple of tasks This allows for the syntax task_a &amp; task_b when defining dependencies for another graph</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[Task, Tuple[Task, ...]]</code> <p>the task being <code>anded</code> with this task</p> required <p>Returns:</p> Type Description <code>Tuple[Task, ...]</code> <p>a tuple of this task and the one being added</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __and__(self: Task, other: Union[Task, Tuple[Task, ...]]) -&gt; Tuple[Task, ...]:\n    \"\"\"\n    Binary and operator for the task or a tuple of tasks\n    This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n    :param other: the task being `anded` with this task\n    :return: a tuple of this task and the one being added\n    \"\"\"\n    return (self, other) if isinstance(other, Task) else (self, *other)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Executes the function within the task</p> <p>Returns:</p> Type Description <code>Union[_T, Awaitable[_T]]</code> <p>the results of the execution, if the function is async this will return the awaitable</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; Union[_T, Awaitable[_T]]:\n    \"\"\"\n    Executes the function within the task\n\n    :return: the results of the execution, if the function is async this will return the awaitable\n    \"\"\"\n    return self.func(*args, **kwargs)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)</p> <p>Returns:</p> Type Description <code>int</code> <p>the hash for the task, which is a hash of the name</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __hash__(self: Task) -&gt; int:\n    \"\"\"\n    Hash function for the task, this lets it be stored in hashable types (sets, as dict keys etc...)\n\n    :return: the hash for the task, which is a hash of the name\n    \"\"\"\n    return hash(self.name)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.__init__","title":"<code>__init__(func, dependencies=None, output_names=None, *, pre_call=None, post_call=None, init_kwargs=None, name=None, _graph=None)</code>","text":"<p>Initialize a Task object.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Union[Any, Awaitable[Any]]]</code> <p>The function that the task is wrapping</p> required <code>dependencies</code> <code>Optional[Union[Task, Tuple[Task, ...]]]</code> <p>The dependencies of the task, defaults to None</p> <code>None</code> <code>output_names</code> <code>Optional[Tuple[str, ...]]</code> <p>The names of the outputs of the task, defaults to None</p> <code>None</code> <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>The function to call with the results of the dependencies for this task, defaults to None</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>The function to call with the output of this task, defaults to None</p> <code>None</code> <code>init_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>The optional initialization arguments for the task if not provided all input arguments will be provided by the dependency results, defaults to None</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>The optional name for this task, defaults to None</p> <code>None</code> <code>_graph</code> <code>Optional[Graph]</code> <p>The optional graph for this task, defaults to None</p> <code>None</code> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __init__(\n    self,\n    func: Callable[..., Union[Any, Awaitable[Any]]],\n    dependencies: Optional[Union[Task, Tuple[Task, ...]]] = None,\n    output_names: Optional[Tuple[str, ...]] = None,\n    *,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    init_kwargs: Optional[Dict[str, Any]] = None,\n    name: Optional[str] = None,\n    _graph: Optional[Graph] = None,\n):\n    \"\"\"\n    Initialize a Task object.\n\n    :param func: The function that the task is wrapping\n    :param dependencies: The dependencies of the task, defaults to None\n    :param output_names: The names of the outputs of the task, defaults to None\n    :param pre_call: The function to call with the results of the dependencies for this task, defaults to None\n    :param post_call: The function to call with the output of this task, defaults to None\n    :param init_kwargs: The optional initialization arguments for the task if not provided all input arguments will\n    be provided by the dependency results, defaults to None\n    :param name: The optional name for this task, defaults to None\n    :param _graph: The optional graph for this task, defaults to None\n    \"\"\"\n    self.func = func\n    self.output_names: Tuple[str, ...] = output_names if output_names is not None else ()\n    self.pre_call = pre_call\n    self.post_call = post_call\n    self.init_kwargs = init_kwargs\n    self.name = name if name is not None else str(uuid4())\n    self._graph = _graph\n\n    if dependencies is None:\n        self.dependencies = ()\n    elif isinstance(dependencies, Task):\n        self.dependencies = (dependencies,)\n    else:\n        self.dependencies = cast(Tuple[Task, ...], dependencies)\n\n    if len(self.dependencies) &gt; 0:\n        for dependent_task in self.dependencies:\n            self._set_graph(dependent_task)\n    elif self._graph is not None:  # For task graphs where no dependencies are provided\n        cast(Graph, self.graph) + self\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.__rand__","title":"<code>__rand__(other)</code>","text":"<p>Binary rand operator for the task or a tuple of tasks This allows for the syntax task_a &amp; task_b when defining dependencies for another graph</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Task</code> <p>the task being <code>anded</code> with this task</p> required <p>Returns:</p> Type Description <code>Tuple[Task, ...]</code> <p>a tuple of this task and the one being added</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def __rand__(self: Task, other: Task) -&gt; Tuple[Task, ...]:\n    \"\"\"\n    Binary rand operator for the task or a tuple of tasks\n    This allows for the syntax task_a &amp; task_b when defining dependencies for another graph\n\n    :param other: the task being `anded` with this task\n    :return: a tuple of this task and the one being added\n    \"\"\"\n    return (other, self) if isinstance(other, Task) else (*other, self)\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.Task.from_dict","title":"<code>from_dict(task_dict, func_map=None)</code>  <code>classmethod</code>","text":"<p>Create a task from a dictionary</p> <p>Parameters:</p> Name Type Description Default <code>task_dict</code> <code>Dict[str, Any]</code> <p>the dictionary of the task</p> required <code>func_map</code> <code>Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]]</code> <p>the mapping of the function names to the functions</p> <code>None</code> <p>Returns:</p> Type Description <code>Task</code> <p>the task object</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls: Type[Task],\n    task_dict: Dict[str, Any],\n    func_map: Optional[Dict[str, Callable[..., Union[_T, Awaitable[_T]]]]] = None,\n) -&gt; Task:\n    \"\"\"\n    Create a task from a dictionary\n\n    :param task_dict: the dictionary of the task\n    :param func_map: the mapping of the function names to the functions\n    :return: the task object\n    \"\"\"\n    func = task_dict.pop(\"func\")\n    if func_map and func in func_map:\n        task = cls(func_map[func], **task_dict)\n    else:\n        # Attempt to import the function dynamically\n        module_name, func_name = func.rsplit(\".\", 1)\n        module = import_module(module_name)\n        # Check type of func to ensure it is a callable\n        func = getattr(module, func_name)\n        if not isinstance(func, Callable):\n            raise ValueError(f\"Function {func_name} in module {module_name} is not callable.\")\n        func = cast(Callable[..., Union[_T, Awaitable[_T]]], func)\n        task = cls(func, **task_dict)\n    task_dict[\"func\"] = func\n    return task\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.aexecute_graph","title":"<code>aexecute_graph(graph, pre_call=None, post_call=None, raise_immediately=True, tasks_semaphore=None)</code>  <code>async</code>","text":"<p>Asynchronously execute the graph</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>graph to execute</p> required <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>tasks_semaphore</code> <code>Optional[Semaphore]</code> <p>the semaphore to control the number of tasks running concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>GraphResults</code> <p>the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>async def aexecute_graph(\n    graph: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    tasks_semaphore: Optional[asyncio.Semaphore] = None,\n) -&gt; GraphResults:\n    \"\"\"\n    Asynchronously execute the graph\n\n    :param graph: graph to execute\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precendence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param tasks_semaphore: the semaphore to control the number of tasks running concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: the result of the graph execution\n    \"\"\"\n    if graph._results:\n        return graph._results\n    graph.low_level_graph.prepare()\n    result_queue = asyncio.Queue()\n    results: Dict[Task, Union[Any, Tuple[Any, ...]]] = {}\n    while graph.low_level_graph.is_active():\n        available_tasks = graph.low_level_graph.get_ready()\n        eligible_tasks = _get_eligble_tasks(available_tasks, results) if not raise_immediately else available_tasks\n        for available_task in eligible_tasks:\n            available_task = cast(Task, available_task)\n            if not available_task.is_async:\n\n                @wraps(available_task.func)\n                async def async_wrapper(*args, **kwargs) -&gt; Any:\n                    return available_task.func(*args, **kwargs)\n\n                executing_func = async_wrapper\n            else:\n                executing_func = cast(Callable[..., Awaitable[Any]], available_task.func)\n            call_args, call_kwargs = _get_args_from_dependencies(available_task.dependencies, results)\n            task_pre_call = available_task.pre_call if available_task.pre_call else pre_call\n            call_kwargs = _execute_pre_call(task_pre_call, available_task, *call_args, **call_kwargs)\n            if available_task.init_kwargs:\n                call_kwargs.update(available_task.init_kwargs)\n            # TODO: Look into using asyncio.wait instead of the queue, assumption is possible speed improvement?\n            asyncio.create_task(\n                _aproducer(available_task, executing_func(*call_args, **call_kwargs), result_queue, tasks_semaphore)\n            )\n        task, result = await _aconsumer(result_queue, raise_immediately)\n        _execute_post_call(post_call, task, result, results)\n        graph.low_level_graph.done(task)\n        results[task] = result\n    graph._results = GraphResults({task.name: result for task, result in results.items()})\n    return graph._results\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.delete_graph","title":"<code>delete_graph(graph_name)</code>","text":"<p>Delete a graph by name from the global graph dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to delete</p> required Source code in <code>src/taskade/_execution.py</code> <pre><code>def delete_graph(graph_name: str) -&gt; None:\n    \"\"\"\n    Delete a graph by name from the global graph dictionary.\n\n    :param graph_name: The name of the graph to delete\n    \"\"\"\n    del _get_graph()[graph_name]\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.execute_graph","title":"<code>execute_graph(graph, pre_call=None, post_call=None, raise_immediately=True, concurrency_pool=ThreadPoolExecutor, n_jobs=None)</code>","text":"<p>Execute the graph with optional concurrency</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>graph to execute</p> required <code>pre_call</code> <code>Optional[PreCallProtocol]</code> <p>default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through</p> <code>None</code> <code>post_call</code> <code>Optional[PostCallProtocol]</code> <p>default post_call function to use for execution, task level post_call functions take precedence over this, defaults to None</p> <code>None</code> <code>raise_immediately</code> <code>bool</code> <p>indicates if any exception raised by a node in the graph should be raised immediately, if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True</p> <code>True</code> <code>concurrency_pool</code> <code>Union[ThreadPoolExecutor, ProcessPoolExecutor, Type[ThreadPoolExecutor], Type[ProcessPoolExecutor]]</code> <p>pool for executing a graph concurrently, this pool will be used for executing the individual tasks, can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThreadPoolExecutor type</p> <code>ThreadPoolExecutor</code> <code>n_jobs</code> <code>Optional[int]</code> <p>optional number of jobs for executing a graph concurrently, defaults to None</p> <code>None</code> <p>Returns:</p> Type Description <code>GraphResults</code> <p>the result of the graph execution</p> <p>Raises:</p> Type Description <code>FailedDependencyError</code> <p>if all available nodes are waiting on a dependency that has failed and raise_immmediately is False</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def execute_graph(\n    graph: Graph,\n    pre_call: Optional[PreCallProtocol] = None,\n    post_call: Optional[PostCallProtocol] = None,\n    raise_immediately: bool = True,\n    concurrency_pool: Union[\n        ThreadPoolExecutor, ProcessPoolExecutor, Type[ThreadPoolExecutor], Type[ProcessPoolExecutor]\n    ] = ThreadPoolExecutor,\n    n_jobs: Optional[int] = None,\n) -&gt; GraphResults:\n    \"\"\"\n    Execute the graph with optional concurrency\n\n    :param graph: graph to execute\n    :param pre_call: default pre_call function to use for execution, task level pre_call functions take precedence over this, defaults to pass_through\n    :param post_call: default post_call function to use for execution, task level post_call functions take precedence over this, defaults to None\n    :param raise_immediately: indicates if any exception raised by a node in the graph should be raised immediately,\n    if False the graph will continue to execute as long as there are nodes that are not dependent on a failed task, defaults to True\n    :param concurrency_pool: pool for executing a graph concurrently, this pool will be used for executing the individual tasks,\n    can either provide an instance of a thread or process pool or specify the type of pool and set the n_jobs parameter, defaults to ThreadPoolExecutor type\n    :param n_jobs: optional number of jobs for executing a graph concurrently, defaults to None\n    :raises FailedDependencyError: if all available nodes are waiting on a dependency that has failed and raise_immmediately is False\n    :return: the result of the graph execution\n    \"\"\"\n    if graph._results:\n        return graph._results\n    if isinstance(concurrency_pool, (ThreadPoolExecutor, ProcessPoolExecutor)):\n        result = _concurrent_execute_graph(graph, concurrency_pool, pre_call, post_call, raise_immediately)\n    elif n_jobs and concurrency_pool in (ThreadPoolExecutor, ProcessPoolExecutor):\n        with concurrency_pool(max_workers=n_jobs) as pool:\n            result = _concurrent_execute_graph(graph, pool, pre_call, post_call, raise_immediately)\n    else:\n        result = _sync_execute_graph(graph, pre_call, post_call, raise_immediately)\n    graph._results = result\n    return graph._results\n</code></pre>"},{"location":"reference/taskade/_execution/#taskade._execution.get_graph","title":"<code>get_graph(graph_name)</code>","text":"<p>Retrieve a graph by name from the global graph dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>graph_name</code> <code>str</code> <p>The name of the graph to retrieve</p> required <p>Returns:</p> Type Description <code>Optional[Graph]</code> <p>The retrieved Graph object or None if not found</p> Source code in <code>src/taskade/_execution.py</code> <pre><code>def get_graph(graph_name: str) -&gt; Optional[Graph]:\n    \"\"\"\n    Retrieve a graph by name from the global graph dictionary.\n\n    :param graph_name: The name of the graph to retrieve\n    :return: The retrieved Graph object or None if not found\n    \"\"\"\n    return _get_graph().get(graph_name)\n</code></pre>"},{"location":"reference/taskade/_types/","title":"_types","text":""},{"location":"reference/taskade/_types/#taskade._types.PoolExecutor","title":"<code>PoolExecutor = TypeVar('PoolExecutor', bound=Union[Union[Union[ThreadPoolExecutor, ProcessPoolExecutor], Type[ThreadPoolExecutor]], Type[ProcessPoolExecutor]])</code>  <code>module-attribute</code>","text":"<p>Type variable for the pool type passed to concurrent execution</p>"},{"location":"reference/taskade/cgraphlib/","title":"cgraphlib","text":"<p>C implementation of TopologicalSorter</p>"},{"location":"reference/taskade/cgraphlib/#taskade.cgraphlib.__doc__","title":"<code>__doc__ = 'C implementation of TopologicalSorter'</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.</p>"},{"location":"reference/taskade/cgraphlib/#taskade.cgraphlib.__file__","title":"<code>__file__ = '/home/octalbits/git/taskade/src/taskade/cgraphlib.cpython-310-x86_64-linux-gnu.so'</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.</p>"},{"location":"reference/taskade/cgraphlib/#taskade.cgraphlib.__name__","title":"<code>__name__ = 'taskade.cgraphlib'</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.</p>"},{"location":"reference/taskade/cgraphlib/#taskade.cgraphlib.__package__","title":"<code>__package__ = 'taskade'</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to 'strict'.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#task-creation","title":"Task Creation","text":"<p>You can create tasks by initializing a Task:</p> <pre><code>from taskade import Task\n\ndef task_a_func():\n    return \"Task A\"\n\ndef task_b_func(result_a):\n    return f\"Task B received {result_a}\"\n\ndef task_c_func(result_a, result_b):\n    return f\"Task C recieved {result_a} &amp; {result_b}\n\ndef main():\n    task_a = Task(\n        name=\"task_a\",\n        func=task_a_func,\n    )\n\n    # You can set output names, one per output of the function, \n    # these will be passed as kwargs to all of its dependencies\n    task_b = Task(\n        name=\"task_b\",\n        func=task_b_func,\n        dependencies=task_a\n        output_names=\"task_b\" \n    )\n\n    task_c = Task(\n        name=\"task_c\",\n        func=task_b_func,\n        dependencies=task_a &amp; task_b, # Notice how dependencies can be tied together with &amp;\n        output_names=\"task_c\"\n    )\n\n    # A graph is implicitly created once task_b is created\n    # because it has a dependency on task_a\n    # The graph can be accessed using any task part of the graph.\n    graph = task_a.graph\n\n    # Now you can execute the graph\n    results = graph()\n    print(results)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Tasks can be sync, async or a mixture of the two. </p> <p>Implicit</p> <p>Note that we don't need to set the graph_name argument when creating the tasks, because a graph is implicitly created once task_b is created due to its dependency on task_a.</p> <p>Note</p> <p>When tasks are created without a <code>graph_name</code> the graph cannot be retrieved with the get_graph method.</p>"},{"location":"usage/#task-decorators","title":"Task Decorators","text":"<p>You can create tasks using the @task decorator:</p> <pre><code>from taskade import task\n\n@task(graph_name=\"my_graph\")\ndef task_a():\n    return \"Task A\"\n\n@task(graph_name=\"my_graph\", dependencies=task_a, name=\"b\") \ndef task_b():\n    return \"Task B\"\n\n@task(graph_name=\"my_graph\", dependencies=\"b\") # Task b can be referred to by name\ndef task_c():\n    return \"Task C\"\n</code></pre>"},{"location":"usage/#explict-graph-creation","title":"Explict Graph Creation","text":"<p>Creating a Graph object and adding tasks to it:</p> <pre><code>from taskade import Graph\n\ngraph = Graph(name=\"my_graph\")\ngraph += task_a\ngraph += task_b\ngraph += task_c\n</code></pre>"},{"location":"usage/#executing-a-graph","title":"Executing a Graph","text":"<p>You can execute a graph using the <code>__call__</code> method:</p> <p><pre><code>results = graph()\n</code></pre> If the graph had any async tasks then the <code>__call__</code> will return an [Awaitable] so we have to <code>await</code> the call method.</p> <pre><code>results = await graph()\n</code></pre> <p>Or with custom pre and post call functions:</p> <pre><code>results = graph()\n</code></pre>"},{"location":"usage/#retrieving-task-results","title":"Retrieving Task Results","text":"<p>When a graph is executed, the execution method returns a dictionary where the keys are the task objects and the values are the results of the tasks. You can retrieve the result of a task by indexing the dictionary with the task object itself:</p> <pre><code>results = graph()\n\n# Get the result of task_a\nresult_a = results[task_a]\nprint(result_a)  # Output: \"Task A\"\n\n# Get the result of task_b\nresult_b = results[task_b]\nprint(result_b)  # Output: \"Task B\"\n\n# Get the result of task_c\nresult_c = results[task_c]\nprint(result_c)  # Output: \"Task C\"\n</code></pre> <p>This allows you to easily access the results of individual tasks after executing the graph. Note that if a task raises an exception during execution, the corresponding value in the results dictionary will be the exception object itself. You can check if a task raised an exception by using the isinstance function:</p> <pre><code>if isinstance(results[task_a], Exception):\n    print(\"Task A raised an exception\")\nelse:\n    print(\"Task A executed successfully\")\n</code></pre>"},{"location":"usage/#pre-and-post-call-functions","title":"Pre and Post Call Functions","text":"<p>Pre and post call functions are optional functions that can be executed before and after a task is executed, respectively. They can be used to perform setup or teardown operations, logging, or any other actions that need to be taken in conjunction with the task execution.</p> <p>Using Pre and Post Call Functions You can pass pre and post call functions to the graph execution method:</p> <pre><code>def pre_call(task, *args, **kwargs):\n    print(f\"Pre-call for {task=}\")\n\ndef post_call(result, *args):\n    print(\"Post-call\")\n\nresults = graph(pre_call=pre_call, post_call=post_call)\n</code></pre> <p>Pre and Post Call functions can be set either at the task level, graph execution level or both. The task level Pre and Post call functions will always take precendence over the graph level version.</p>"},{"location":"usage/#calling-tasks-outside-of-taskade","title":"Calling Tasks Outside of Taskade","text":"<p>Even though a function is decorated with @task, it can still be called outside of the Taskade framework just like a normal function:</p> <pre><code>result = task_a()\nprint(result)  # Output: \"Task A\"\n</code></pre> <p>This allows you to test or use your tasks independently of the Taskade framework.</p> <p>To see even more advanced functionality check out the advanced usage</p>"},{"location":"usage/advanced_usage/","title":"Advanced Usage","text":""},{"location":"usage/advanced_usage/#using-multiple-task-decorators","title":"Using Multiple Task Decorators","text":"<p>You can use multiple task decorators on a single function to create multiple tasks with different dependencies and settings:</p> <pre><code>from taskade import task\n\n@task(graph_name=\"graph1\", dependencies=(\"task_b\",), name=\"task_a_1\", output_names=(\"result_a\",))\n@task(graph_name=\"graph1\", dependencies=(\"task_c\",), name=\"task_a_2\", output_names=(\"result_b\",))\n@task(graph_name=\"graph2\", dependencies=(\"task_d\",), name=\"task_a_3\", output_names=(\"result_c\",))\ndef task_a(arg):\n    return arg\n\n@task(graph_name=\"graph1\")\ndef task_b():\n    return \"Task B\"\n\n@task(graph_name=\"graph1\")\ndef task_c():\n    return \"Task C\"\n\n@task(graph_name=\"graph2\")\ndef task_d():\n    return \"Task D\"\n\n@task(graph_name=\"graph1\", dependencies=(\"task_a_1\", \"task_a_2\"))\ndef task_e(result_a, result_b):\n    return result_a, result_b\n</code></pre> <p>In this example, <code>task_a</code> takes an argument arg and returns it. The output names are specified as <code>result_a</code>, <code>result_b</code>, and <code>result_c</code> for each of the tasks created by the multiple decorators. <code>task_e</code> depends on <code>task_a_1</code> and <code>task_a_2</code>, and takes two arguments <code>result_a</code> and <code>result_b</code>, which are the outputs of <code>task_a_1</code> and <code>task_a_2</code> respectively. Note that the number of arguments in task_e matches the number of outputs from the dependencies <code>task_a_1</code> and <code>task_a_2</code>.</p>"},{"location":"usage/advanced_usage/#init-kwargs","title":"Init Kwargs","text":"<p>You can pass initialization keyword arguments to tasks using the <code>init_kwargs</code> parameter:</p> <pre><code>from taskade import task\n\n@task(graph_name=\"graph\", init_kwargs={\"foo\": \"bar\"})\ndef task_a(foo):\n    return foo\n\ngraph = task_a.graph\nresults = graph()\nprint(results[task_a])  # Output: \"bar\"\n</code></pre> <p>This passes the foo keyword argument to <code>task_a</code> when it's executed.</p>"},{"location":"usage/advanced_usage/#using-output-names","title":"Using Output Names","text":"<p>You can specify output names for tasks using the <code>output_names</code> parameter:</p> <pre><code>from taskade import task\n\n@task(graph_name=\"graph\", output_names=[\"result_a\", \"result_b\"])\ndef task_a():\n    return \"Result A\", \"Result B\"\n\n@task(graph_name=\"graph\", dependencies=[\"task_a\"], init_kwargs={\"result_a\": None, \"result_b\": None})\ndef task_b(result_a, result_b):\n    return result_a, result_b\n\ngraph = task_a.graph\nresults = graph()\nprint(results[task_b])  # Output: (\"Result A\", \"Result B\")\n</code></pre> <p>This sets the output names of <code>task_a</code> to <code>result_a</code> and <code>result_b</code>, and passes these outputs as keyword arguments to <code>task_b</code>.</p>"},{"location":"usage/advanced_usage/#creation-from-dictionary","title":"Creation from Dictionary","text":"<p>You can create a graph from a dictionary of tasks:</p> <pre><code>from taskade import Graph, task\n\ntasks = {\n    \"task_a\": task_a,\n    \"task_b\": task_b,\n    \"task_c\": task_c,\n}\n\ngraph = Graph.from_dict(tasks, name=\"my_graph\")\nresults = graph()\nprint(results)\n</code></pre> <p>This creates a graph with the tasks in the dictionary and executes it.</p>"},{"location":"usage/advanced_usage/#controlling-concurrency","title":"Controlling Concurrency","text":""},{"location":"usage/advanced_usage/#async-execution","title":"Async Execution","text":"<p>You can control the concurrency of async execution by passing an async semaphore to the graph's <code>__call__</code> method:</p> <pre><code>from taskade import task, get_graph\n\n@task(graph_name=\"my_graph\", output_names=[\"result_a\"])\nasync def task_a():\n    return \"Result A\"\n\n@task(graph_name=\"my_graph\", dependencies=(task_a, ), input_names=[\"result_a\"])\nasync def task_b(result_a):\n    return f\"Task B received {result_a}\"\n\nasync def main():\n    graph = get_graph(\"my_graph\")\n    async with asyncio.Semaphore(5) as semaphore:\n        results = await graph(tasks_semaphore=semaphore)\n        print(results)\n</code></pre>"},{"location":"usage/advanced_usage/#sync-execution","title":"Sync Execution","text":"<p>You can control the concurrency of sync execution by passing a pool to the graph's <code>__call__</code> method:</p> <pre><code>from taskade import task, get_graph\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n\n@task(graph_name=\"my_graph\", output_names=(\"result_a\",))\ndef task_a():\n    return \"Result A\"\n\n@task(graph_name=\"my_graph\", dependencies=(task_a,))\ndef task_b(result_a):\n    return f\"Task B received {result_a}\"\n\ngraph = get_graph(\"my_graph\")\n\nwith ThreadPoolExecutor(max_workers=5) as pool:\n    results = graph(concurrency_pool=pool)\n    print(results)\n\n# or\n\nwith ProcessPoolExecutor(max_workers=5) as pool:\n    results = graph(concurrency_pool=pool)\n    print(results)\n</code></pre> <p>Or you can let taskade manage the pool for you by just passing in the <code>n_jobs</code> parameter. When executing a sync graph concurrently this way you can also pass in the type of pool into the <code>concurency_pool</code> parameter. By default it is set to ThreadPoolExecutor.</p> <pre><code>from taskade import task, get_graph\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n\n@task(graph_name=\"my_graph\", output_names=(\"result_a\",))\ndef task_a():\n    return \"Result A\"\n\n@task(graph_name=\"my_graph\", dependencies=(task_a,))\ndef task_b(result_a):\n    return f\"Task B received {result_a}\"\n\ngraph = get_graph(\"my_graph\")\n\nresults = graph(n_jobs=5)\nprint(results)\n\n# or\n\nresults = graph(n_jobs=5, concurrency_pool=ProcessPoolExecutor)\nprint(results)\n</code></pre> <p>In both examples, the <code>graph_name</code> parameter is used to set the name of the graph, and the get_graph function is used to retrieve the graph. The graph is then called with the concurrency control parameters.</p>"},{"location":"coverage_report/","title":"Coverage Report","text":""}]}